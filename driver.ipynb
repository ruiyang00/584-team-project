{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bb1017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy, deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "continuous-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(data):\n",
    "    # train test split\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "    # get targets out\n",
    "    train_B = train[\"TARGET_B\"]\n",
    "    train_D = train[\"TARGET_D\"]\n",
    "    test_B = test[\"TARGET_B\"]\n",
    "    test_D = test[\"TARGET_D\"]\n",
    "    train.drop(columns = [\"TARGET_D\",\"TARGET_B\"], inplace = True)\n",
    "    test.drop(columns = [\"TARGET_D\",\"TARGET_B\"], inplace = True)\n",
    "    # we need to resample the train data to balance it out\n",
    "    sampler = RandomOverSampler(random_state=50)\n",
    "    x_res, y_res = sampler.fit_resample(train, train_B)\n",
    "    print(\"oversampled to \"+str(x_res.shape[0])+\"data points.\")\n",
    "    \n",
    "    # if dimension_red_model is used, use it on test\n",
    "    #if(dimension_red_model != None):\n",
    "    #    test = dimension_red_model.fit_transform(test)\n",
    "    \n",
    "    # run the model\n",
    "    acc_log, fp_rate_log, fn_rate_log, profit_log = run_regression(x_res, y_res, test, test_B, test_D)\n",
    "    print(\"logistic regression accuracy = \"+str(acc_log))\n",
    "    print(\"logistic regression false positive rate = \"+str(fp_rate_log))\n",
    "    print(\"logistic regression false negative rate = \"+str(fn_rate_log))    \n",
    "    print(\"logistic regression profit = \"+str(profit_log))\n",
    "    \n",
    "    # run decision tree\n",
    "    acc_tree, fp_rate_tree, fn_rate_tree, profit_tree = run_decision_tree(x_res, y_res, test, test_B, test_D)\n",
    "    print(\"decision tree accuracy = \"+str(acc_tree))\n",
    "    print(\"decision tree false positive rate = \"+str(fp_rate_tree))\n",
    "    print(\"decision tree false negative rate = \"+str(fn_rate_tree))    \n",
    "    print(\"decision tree profit = \"+str(profit_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mechanical-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(x_res, y_res, test, test_B, test_D):\n",
    "    # train the model\n",
    "    clf = DecisionTreeClassifier(max_depth = 20)\n",
    "    clf = clf.fit(x_res, y_res)\n",
    "    \n",
    "    # test on the test set\n",
    "    y_pred = clf.predict(test)\n",
    "    \n",
    "    return get_acc(y_pred, test_B, test_D, 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "enormous-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree(x_res, y_res, test, test_B, test_D):\n",
    "    # train the model\n",
    "    clf = LogisticRegression(max_iter = 100, solver = \"liblinear\", verbose = 1)\n",
    "    clf = clf.fit(x_res, y_res)\n",
    "    \n",
    "    # test on the test set\n",
    "    y_pred = clf.predict(test)\n",
    "    \n",
    "    return get_acc(y_pred, test_B, test_D, 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "moderate-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_pred, y_actual, y_donate, mail_cost):\n",
    "    df = pd.concat([pd.Series(y_pred), pd.Series(y_actual), pd.Series(y_donate)], axis = 1)\n",
    "    df.columns = [\"y_pred\", \"y_actual\", \"y_donate\"]\n",
    "    \n",
    "    #get accuracy\n",
    "    accuracy = df[(df['y_pred'] == df['y_actual'])].shape[0] / y_actual.shape[0]\n",
    "    # get false positive rate\n",
    "    fp_rate = df[(df['y_pred'] == 1) & (df['y_actual'] == 0)].shape[0] / y_actual.shape[0]\n",
    "    # get false negative rate\n",
    "    fn_rate = df[(df['y_pred'] == 0) & (df['y_actual'] == 1)].shape[0] / y_actual.shape[0]\n",
    "    # get total profit \n",
    "    profit = df[(df['y_pred'] == 1) & (df['y_actual'] == 1)][\"y_donate\"].sum() - df[(df['y_pred'] == 1)].shape[0]*mail_cost\n",
    "    \n",
    "    return accuracy, fp_rate, fn_rate, profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b70cc93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(df): \n",
    "    def split_types(in_dict):\n",
    "        res = collections.defaultdict(list)\n",
    "        for key, val in in_dict.items():\n",
    "            if key in selected_features:\n",
    "                res[val].append(key)\n",
    "        return res\n",
    "\n",
    "    def clean_whitespace_in_features(df):\n",
    "        for column in df.columns:\n",
    "            uniques = df[column].unique()\n",
    "            if len(uniques) == 2 and ' ' in uniques:\n",
    "                if is_string_dtype(df[column]):\n",
    "                    df.loc[:,column] = df[:,column].replace(to_replace=' ', value='0')\n",
    "                else:\n",
    "                    df[:,column] = df[:,column].replace(to_replace=' ', value=0)    \n",
    "            \n",
    "            if len(uniques) > 2 and ' ' in uniques:\n",
    "                df[:,column] = df[:,column].replace(to_replace=' ', value=np.nan)\n",
    "\n",
    "    def get_df_data_types(df):\n",
    "        for column in df.columns:\n",
    "            print(column, df[column].unique())\n",
    "\n",
    "    def get_wrong_types(df, in_dict):\n",
    "        res = collections.defaultdict(list)\n",
    "        for column in df.columns:\n",
    "            if column in in_dict['Num'] and not is_numeric_dtype(df[column]):\n",
    "                res['Num'] = column\n",
    "            \n",
    "            if column in in_dict['Char'] and not is_string_dtype(df[column]):\n",
    "                res['Char'] = column\n",
    "        return res;\n",
    "\n",
    "    def replace_string_type_missing_values(string_types, df):\n",
    "        for col in string_types:\n",
    "            counts = len(df[col].unique())\n",
    "            if counts == 2:\n",
    "                df.loc[:,col] = df.loc[:,col].replace(to_replace=' ', value='Q')\n",
    "            elif counts > 2:\n",
    "                df.loc[:,col] = df.loc[:,col].replace(to_replace=' ', value=np.nan)         \n",
    "            \n",
    "    def replace_numeric_type_missing_values(num_types, df):\n",
    "        for col in num_types:\n",
    "            counts = len(df[col].unique())\n",
    "            if counts == 2:\n",
    "                df.loc[:,col] = df.loc[:,col].replace(r'\\s.*$', value=9, regex=True)\n",
    "            elif counts > 2:\n",
    "                df.loc[:,col] = df.loc[:,col].replace(r'\\s.*$', value=np.nan, regex=True)\n",
    "            \n",
    "    def perform_one_hot_encoding(list_attributes, df):\n",
    "        for attr in list_attributes:\n",
    "            pd.get_dummies(df[attr], prefix=attr)   \n",
    "    ##some features had to manual preprocess#####\n",
    "    ###truncate the ZIP atrribute to length=5####\n",
    "    \n",
    "    # need to be done first\n",
    "    for key in ['NOEXCH', 'RECINHSE', 'RECP3', 'RECPGVG', 'RECSWEEP']:\n",
    "        df.loc[df[key].isin([\"0\", \"1\", \" \", 0, 1]), key]= 0\n",
    "        df.loc[df[key].isin([\"X\"]), key] = 1\n",
    "    \n",
    "    type_dict = pd.read_csv('otype1.txt', header=None, index_col=0, squeeze=True).to_dict()\n",
    "    type_list = split_types(type_dict)   \n",
    "    \n",
    "    df.loc[:,'RFA_2F'] = df.loc[:,'RFA_2F'].astype(str)\n",
    "    df.loc[:,'ZIP'] = df.loc[:,'ZIP'].astype(str)\n",
    "    df.loc[:,'ZIP'] = df.loc[:,'ZIP'].str.slice(0,5)\n",
    "    \n",
    "    ''' General:\n",
    "        replacing any value with period or/and whitespace\n",
    "    '''\n",
    "    \n",
    "    #whitesapce \\s\n",
    "    replace_string_type_missing_values(type_list['Char'], df)\n",
    "    replace_numeric_type_missing_values(type_list['Num'], df)\n",
    "    \n",
    "    # df.drop(labels=['CONTROLN'], axis = 1)\n",
    "    \n",
    "    ####Fields Containing Constants################\n",
    "    df.dropna(axis=1, thresh= 2, inplace=True)\n",
    "    \n",
    "    ####dealing with missing features#################   \n",
    "    #1. drop the attribute if missing values >= 99.5%\n",
    "    #calculating the dropping_treshold \n",
    "    num_rows = len(df)\n",
    "    perc = 99.5\n",
    "    min_count =  int(((100-perc)/100)*num_rows+ 1)\n",
    "    df.dropna(axis = 1, thresh=min_count)\n",
    "    \n",
    "    #2. if features contains NAN < 99.5% we need to replace NAN with the most frequent value\n",
    "    #this line does replace differnet attribute types(Number, char, boolean, etc)  with the most frequent\n",
    "    # value\n",
    "    df.fillna(df.mode().iloc[0], inplace=True)\n",
    "    \n",
    "    ### categorical data ##########\n",
    "    for key in type_list['Char']:\n",
    "        mapping = {k: v for v, k in enumerate(df[key].unique())} \n",
    "        df[key].replace(mapping, inplace=True)\n",
    "    ####Time Frame and Date Fields#########\n",
    "    end_date = 9706\n",
    "    for time_key in ['MAXADATE', 'MINRDATE', 'MAXRDATE', 'LASTDATE', 'FISTDATE', 'NEXTDATE', 'ODATEDW']: \n",
    "        end_date = pd.to_datetime(end_date, format='%y%m', exact=True)\n",
    "        df.loc[df[time_key] == 0, time_key] = df[time_key].mode()\n",
    "        start_date = temp_date_attr = pd.to_datetime(df[time_key], format='%y%m', exact=True)\n",
    "        df.loc[:,time_key] = (end_date - start_date).dt.days\n",
    "    df.fillna(df.mode().iloc[0], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hollywood-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_compress(data, var=0.95):\n",
    "    # get pca\n",
    "    pca_dims = PCA()\n",
    "    pca_dims.fit(data)\n",
    "    cumsum = np.cumsum(pca_dims.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum >= var) + 1\n",
    "    pca = PCA(n_components=d)\n",
    "    output = pca.fit_transform(data)\n",
    "    return output, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-ideal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wayne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "c:\\users\\wayne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "<ipython-input-33-ee2023a334d2>:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=1, thresh= 2, inplace=True)\n",
      "c:\\users\\wayne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "c:\\users\\wayne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4575: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "pd.get_option(\"display.max_columns\")\n",
    "df = pd.read_csv(\"cup98lrn.txt\", sep=',', error_bad_lines = False, low_memory = False, skip_blank_lines = True)\n",
    "\n",
    "selected_features = [\n",
    "    'TARGET_D', 'TARGET_B',\n",
    "    'OSOURCE', 'ZIP', 'PVASTATE', 'DOB', 'NOEXCH', 'RECP3', 'RECINHSE', 'RECPGVG', 'RECSWEEP', 'DOMAIN', 'CLUSTER', 'AGE', 'HOMEOWNR', 'NUMCHLD', 'INCOME', 'GENDER', 'WEALTH1', 'HIT', 'PUBNEWFN', 'MALEMILI', 'MALEVET', 'VIETVETS', 'WWIIVETS', 'LOCALGOV', 'STATEGOV', 'FEDGOV', 'WEALTH2', 'COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO', 'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS', 'WALKER', 'KIDSTUFF', 'CARDS', 'PLATES', 'LIFESRC', 'ETH3', 'ETH8', 'ETH10', 'ETH11', 'ETH15', 'OEDC1', 'OEDC2', 'OEDC3', 'CARDPROM', 'MAXADATE', 'NUMPROM', 'CARDPM12', 'NUMPRM12', 'RAMNTALL', 'NGIFTALL', 'CARDGIFT', 'MINRAMNT', 'MINRDATE', 'MAXRAMNT', 'MAXRDATE', 'LASTGIFT', 'LASTDATE', 'FISTDATE', 'NEXTDATE', \n",
    "    'TIMELAG', 'AVGGIFT', 'RFA_2R', 'RFA_2F', 'RFA_2A', 'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A', 'CLUSTER2', 'GEOCODE2', 'ODATEDW']\n",
    "\n",
    "# print(df[selected_features])\n",
    "# df[selected_features].to_csv('selected_features.csv', index=False)\n",
    "\n",
    "data_trimmed = preprocessing_data(df[selected_features])\n",
    "targets = deepcopy(data_trimmed[['TARGET_D', 'TARGET_B']])\n",
    "data_trimmed.drop(columns = [\"TARGET_D\",\"TARGET_B\"], inplace = True)\n",
    "#pd.get_dummies(data_trimmed).shape\n",
    "\n",
    "#data, pca_model = pca_compress(pd.get_dummies(data_trimmed))\n",
    "#data = pd.concat([pd.DataFrame(data),targets], axis = 1)\n",
    "#compare_models(data, pca_model)\n",
    "data = pd.concat([data_trimmed,targets], axis = 1)\n",
    "compare_models(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "military-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>...</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>ODATEDW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>215</td>\n",
       "      <td>5042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>38</td>\n",
       "      <td>3614</td>\n",
       "      <td>0</td>\n",
       "      <td>5001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>4</td>\n",
       "      <td>4181</td>\n",
       "      <td>0</td>\n",
       "      <td>3801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>144</td>\n",
       "      <td>5559</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>12.146341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>122</td>\n",
       "      <td>4477</td>\n",
       "      <td>0</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>96.794872</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OSOURCE   ZIP  PVASTATE   DOB  NOEXCH  RECP3  RECINHSE  RECPGVG  \\\n",
       "0            0     0         0  3712       0      0         0        0   \n",
       "1            1     1         0  5202       0      0         0        0   \n",
       "2            2     2         0     0       0      0         0        0   \n",
       "3            3     3         0  2801       0      0         0        0   \n",
       "4            4     4         0  2001       0      1         1        0   \n",
       "...        ...   ...       ...   ...     ...    ...       ...      ...   \n",
       "95407      215  5042         0     0       0      0         0        0   \n",
       "95408       38  3614         0  5001       0      0         0        0   \n",
       "95409        4  4181         0  3801       0      1         0        0   \n",
       "95410      144  5559         0  4005       0      0         1        0   \n",
       "95411      122  4477         0  1801       0      0         1        1   \n",
       "\n",
       "       RECSWEEP  DOMAIN  ...    AVGGIFT  RFA_2R  RFA_2F  RFA_2A  MDMAUD_R  \\\n",
       "0             0       0  ...   7.741935       0       0       0         0   \n",
       "1             0       1  ...  15.666667       0       1       1         0   \n",
       "2             0       2  ...   7.481481       0       0       0         0   \n",
       "3             0       2  ...   6.812500       0       0       0         0   \n",
       "4             0       3  ...   6.864865       0       1       2         0   \n",
       "...         ...     ...  ...        ...     ...     ...     ...       ...   \n",
       "95407         0       7  ...  25.000000       0       2       1         0   \n",
       "95408         0       8  ...  20.000000       0       2       2         0   \n",
       "95409         0      12  ...   8.285714       0       3       0         0   \n",
       "95410         0       8  ...  12.146341       0       0       2         0   \n",
       "95411         0       8  ...  96.794872       0       2       1         1   \n",
       "\n",
       "       MDMAUD_F  MDMAUD_A  CLUSTER2  GEOCODE2  ODATEDW  \n",
       "0             0         0      39.0         0     3073  \n",
       "1             0         0       1.0         1     1247  \n",
       "2             0         0      60.0         0     2708  \n",
       "3             0         0      41.0         0     3804  \n",
       "4             0         0      26.0         1     4169  \n",
       "...         ...       ...       ...       ...      ...  \n",
       "95407         0         0      12.0         0      517  \n",
       "95408         0         0       2.0         1      517  \n",
       "95409         0         0      34.0         3      882  \n",
       "95410         0         0      11.0         1     4169  \n",
       "95411         1         1      12.0         0     3439  \n",
       "\n",
       "[95412 rows x 81 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "promotional-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4985.253009</td>\n",
       "      <td>574.417863</td>\n",
       "      <td>1511.385755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5089.167940</td>\n",
       "      <td>-2660.176472</td>\n",
       "      <td>779.657210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4850.056243</td>\n",
       "      <td>2777.045872</td>\n",
       "      <td>-1472.103766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4916.279862</td>\n",
       "      <td>2658.300703</td>\n",
       "      <td>2080.920182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4846.241649</td>\n",
       "      <td>4894.031269</td>\n",
       "      <td>2826.571048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>120.930072</td>\n",
       "      <td>-438.894324</td>\n",
       "      <td>-3901.388956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>-1491.629481</td>\n",
       "      <td>-3598.086411</td>\n",
       "      <td>-99.036631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>-871.019142</td>\n",
       "      <td>-2402.413458</td>\n",
       "      <td>-642.359302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>589.510192</td>\n",
       "      <td>1590.121053</td>\n",
       "      <td>2999.666929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>-420.186318</td>\n",
       "      <td>2700.267627</td>\n",
       "      <td>1020.963582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2\n",
       "0     -4985.253009   574.417863  1511.385755\n",
       "1     -5089.167940 -2660.176472   779.657210\n",
       "2     -4850.056243  2777.045872 -1472.103766\n",
       "3     -4916.279862  2658.300703  2080.920182\n",
       "4     -4846.241649  4894.031269  2826.571048\n",
       "...            ...          ...          ...\n",
       "95407   120.930072  -438.894324 -3901.388956\n",
       "95408 -1491.629481 -3598.086411   -99.036631\n",
       "95409  -871.019142 -2402.413458  -642.359302\n",
       "95410   589.510192  1590.121053  2999.666929\n",
       "95411  -420.186318  2700.267627  1020.963582\n",
       "\n",
       "[95412 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-astrology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
